
# Chatbot TÆ° váº¥n TÃ¢m lÃ½

## Giá»›i thiá»‡u
ÄÃ¢y lÃ  má»™t dá»± Ã¡n chatbot há»— trá»£ tÃ¢m lÃ½ Ä‘Æ°á»£c xÃ¢y dá»±ng báº±ng mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n LLaMA-3.2-1B vÃ  Gemini. Má»¥c tiÃªu cá»§a dá»± Ã¡n lÃ  táº¡o ra má»™t há»‡ thá»‘ng chatbot giÃºp há»— trá»£ ngÆ°á»i dÃ¹ng trong viá»‡c Ä‘á»‘i máº·t vá»›i stress vÃ  cÃ¡c váº¥n Ä‘á» tÃ¢m lÃ½ khÃ¡c. Há»‡ thá»‘ng sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ hiá»‡n Ä‘áº¡i Ä‘á»ƒ cung cáº¥p cÃ¡c pháº£n há»“i Ä‘á»“ng cáº£m vÃ  cÃ³ tÃ­nh cháº¥t há»— trá»£.

## ğŸš€ TÃ­nh nÄƒng

* **Semantic Search**: TÃ¬m pháº£n há»“i gáº§n nháº¥t tá»« táº­p Q\&A gá»‘c.
* **Generative Model**: Sinh pháº£n há»“i má»›i khi khÃ´ng cÃ³ cÃ¢u tráº£ lá»i tÆ°Æ¡ng tá»±.
* **PhÃ¢n loáº¡i cáº£m xÃºc**: NhÃ£n 3 lá»›p (Normal, Anxiety, Depression), gá»™p suicidal vÃ o Depression.
* **Gá»£i Ã½ hÃ nh Ä‘á»™ng**: Äá» xuáº¥t phÆ°Æ¡ng phÃ¡p há»— trá»£ phÃ¹ há»£p vá»›i tá»«ng tráº¡ng thÃ¡i.
* **Giao diá»‡n Gradio**: Cho phÃ©p chá»n mÃ´ hÃ¬nh (Llama hoáº·c Gemini), hiá»ƒn thá»‹ lá»‹ch sá»­ trÃ² chuyá»‡n vÃ  lÆ°u log.

## ğŸ“ Cáº¥u trÃºc thÆ° má»¥c

```bash
project_root/
â”œâ”€â”€ app.py                     # Giao diá»‡n Gradio
â”œâ”€â”€ .env                       # Biáº¿n mÃ´i trÆ°á»ng: HF_TOKEN, GEMINI_API_KEY
â”œâ”€â”€ README.md                  # HÆ°á»›ng dáº«n sá»­ dá»¥ng
â”œâ”€â”€ requirements.txt           # CÃ¡c thÆ° viá»‡n cáº§n cÃ i Ä‘áº·t
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ conversations.json     # Dá»¯ liá»‡u Q&A gá»‘c (~950k cáº·p)
â”‚   â””â”€â”€ demo_1000.json         # 1000 máº«u demo Ä‘Ã£ gÃ¡n nhÃ£n
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ chat_logs/             # ThÆ° má»¥c lÆ°u log trÃ² chuyá»‡n
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ llama_model.py
â”‚   â”œâ”€â”€ gemini_api.py
â”‚   â”œâ”€â”€ chatbot_model.py
â”‚   â””â”€â”€ model_router.py
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_loader.py
â”‚   â”œâ”€â”€ semantic_search.py
â”‚   â””â”€â”€ logger.py
â””â”€â”€ scripts/
    â”œâ”€â”€ prepare_data.py        # Chuáº©n bá»‹ demo_1000.json vá»›i label
    â”œâ”€â”€ finetune_qlora.py      # Fine-tune LLaMA vá»›i QLoRA
    â””â”€â”€ run_inference.py       # Cháº¡y inference model fine-tuned
```

## ğŸ’» CÃ i Ä‘áº·t

### 1. Clone repository

```bash
git clone <repo_url>
cd project_root
```

### 2. Táº¡o virtual environment

```bash
python3 -m venv venv
source venv/bin/activate
```

### 3. CÃ i Ä‘áº·t dependencies

```bash
pip install -r requirements.txt
```

### 4. Cáº¥u hÃ¬nh biáº¿n mÃ´i trÆ°á»ng

Táº¡o file `.env` vá»›i ná»™i dung:

```ini
HF_TOKEN=your_huggingface_token_here
GEMINI_API_KEY=your_gemini_api_key_here
```

## ğŸ“Š Cháº¡y demo local

### 1. Chuáº©n bá»‹ dá»¯ liá»‡u demo

```bash
python scripts/prepare_data.py
```

### 2. Fine-tune mÃ´ hÃ¬nh (tÃ¹y chá»n)

```bash
python scripts/finetune_qlora.py
```

### 3. Cháº¡y giao diá»‡n Gradio

```bash
python app.py
```

### 4. Sá»­ dá»¥ng

* Nháº­p tin nháº¯n, chá»n mÃ´ hÃ¬nh Llama hoáº·c Gemini.
* Xem pháº£n há»“i, nhÃ£n cáº£m xÃºc vÃ  gá»£i Ã½ hÃ nh Ä‘á»™ng.
* Lá»‹ch sá»­ trÃ² chuyá»‡n sáº½ hiá»ƒn thá»‹.
* Nháº¥n **LÆ°u láº¡i buá»•i trÃ² chuyá»‡n** Ä‘á»ƒ ghi log.

## ğŸ”§ Triá»ƒn khai

* Dá»… dÃ ng deploy lÃªn HuggingFace Spaces hoáº·c server riÃªng.
* ÄÃ³ng gÃ³i Docker báº±ng cÃ¡ch táº¡o `Dockerfile` vÃ  `docker-compose.yml`.

## ğŸ“ NÃ¢ng cao

* Huáº¥n luyá»‡n mÃ´ hÃ¬nh phÃ¢n loáº¡i riÃªng Ä‘á»ƒ tÄƒng Ä‘á»™ chÃ­nh xÃ¡c.
* Má»Ÿ rá»™ng nhÃ£n (vÃ­ dá»¥: Stress, Loneliness).
* TÃ­ch há»£p chatbot vÃ o website hoáº·c á»©ng dá»¥ng di Ä‘á»™ng.

---

**LiÃªn há»‡**: \[Your Name] â€“ Email: [your\_email@example.com](mailto:your_email@example.com)
